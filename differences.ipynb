{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "import numpy as np\n",
    "from iris import quickplot as qplt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !!mkdir /usr/local/share/notebooks/data/mogreps-gg\n",
    "# !s3fs mogreps-g /usr/local/share/notebooks/data/mogreps-gg -o endpoint=eu-west-2 -o public_bucket=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !!mkdir /usr/local/share/notebooks/data/mogreps-uk\n",
    "# !s3fs mogreps-uk /usr/local/share/notebooks/data/mogreps-uk -o endpoint=eu-west-2 -o public_bucket=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "from boto.s3.connection import S3Connection\n",
    "import os\n",
    "\n",
    "os.environ['S3_USE_SIGV4'] = 'True'\n",
    "\n",
    "def list_files(bucket, prefix='prods', n=100):\n",
    "    conn = S3Connection(host='s3.eu-west-2.amazonaws.com')\n",
    "    bucket = conn.get_bucket(bucket)\n",
    "    results = []\n",
    "    keys = iter(bucket.list(prefix=prefix))\n",
    "    for i in range(n):\n",
    "        try:\n",
    "            results.append(next(keys))\n",
    "        except StopIteration:\n",
    "            pass\n",
    "    return ['{}'.format(k.key) for k in results]\n",
    "\n",
    "\n",
    "g_files = list_files('mogreps-g', 'prods_op_mogreps-g_20160207_00_01', 10000)\n",
    "uk_files = list_files('mogreps-uk', 'prods_op_mogreps-uk_20160207_03_01', 10000)\n",
    "\n",
    "print(len(g_files))\n",
    "print(len(uk_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_info(fname):\n",
    "    segs = fname.split('_')\n",
    "    segs[-1] = segs[-1].split('.')[0]\n",
    "    info = [segs[-4]] + [int(s) for s in segs[-3:]]\n",
    "#     return {'run_hour': info[0], 'member': info[1], 'lead_time': info[2]}\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_ground_level(cube):\n",
    "    '''Minimize height or maximise pressure.'''\n",
    "    if any([re.match('height.*', d.name()) for d in cube.coords()]):\n",
    "        for d in cube.coords():\n",
    "            match = re.match('height.*', d.name())\n",
    "            if match:\n",
    "                name = match.group(0)\n",
    "                vert_coord = cube.coord(name)\n",
    "        ground_level = cube.extract(iris.Constraint(**{name: min(vert_coord.points)}))\n",
    "        \n",
    "    elif any([re.match('pressure.*', d.name()) for d in cube.coords()]):\n",
    "        for d in cube.coords():\n",
    "            match = re.match('pressure.*', d.name())\n",
    "            if match:\n",
    "                name = match.group(0)\n",
    "                vert_coord = cube.coord(name)\n",
    "        ground_level = cube.extract(iris.Constraint(**{name: max(vert_coord.points)}))\n",
    "    \n",
    "    else:\n",
    "        ground_level = cube\n",
    "        name = None\n",
    "    \n",
    "    return (ground_level, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unrotate(uk_cube, g_cube):\n",
    "    glat = uk_cube.coord('grid_latitude').points\n",
    "    glon = uk_cube.coord('grid_longitude').points\n",
    "    x, y = np.meshgrid(glon, glat)\n",
    "    cs = uk_cube.coord_system()\n",
    "    lons, lats = iris.analysis.cartography.unrotate_pole(x, y, cs.grid_north_pole_longitude, cs.grid_north_pole_latitude)\n",
    "    clons = iris.coords.DimCoord(lons[0,:], standard_name='longitude', var_name='longitude', units=g_cube.coord('longitude').units, coord_system=iris.coord_systems.GeogCS(6371229.0))\n",
    "    clats = iris.coords.DimCoord(lats[:,0], standard_name='latitude', var_name='latitude', units=g_cube.coord('latitude').units, coord_system=iris.coord_systems.GeogCS(6371229.0))\n",
    "\n",
    "    uk_unrotate = uk_cube.copy()\n",
    "    uk_unrotate.remove_coord('grid_latitude')\n",
    "    uk_unrotate.add_dim_coord(clats, 0)\n",
    "    uk_unrotate.remove_coord('grid_longitude')\n",
    "    uk_unrotate.add_dim_coord(clons, 1)\n",
    "    return uk_unrotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_uk_from_global(g_cube, uk_cube):\n",
    "    minlat = uk_cube.coord('latitude').points[0]\n",
    "    maxlat = uk_cube.coord('latitude').points[-1]\n",
    "    minlon = uk_cube.coord('longitude').points[0]\n",
    "    maxlon = uk_cube.coord('longitude').points[-1]\n",
    "    \n",
    "    g_cube_uk = g_cube.intersection(latitude=(minlat,maxlat)).intersection(longitude=(minlon,maxlon))\n",
    "    return g_cube_uk.regrid(grid=uk_cube, scheme=iris.analysis.Linear())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_diff(uk_cube, g_cube):   \n",
    "    diff = g_cube - uk_cube\n",
    "    diff.add_aux_coord(uk_cube.coord('time'))\n",
    "    diff.coord('time').var_name = 'time'\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_diffs(param):\n",
    "    diffs = iris.cube.CubeList([])\n",
    "    uks = iris.cube.CubeList([])\n",
    "    gs = iris.cube.CubeList([])\n",
    "    \n",
    "    for fname in uk_files:\n",
    "        info = get_info(fname)\n",
    "        uk_fname = fname\n",
    "        g_fname = 'prods_op_mogreps-g_{}_{:02d}_{:02d}_{:03d}.nc'.format(info[0], info[1]-3, info[2], info[3]+3)\n",
    "\n",
    "        if g_fname in g_files:\n",
    "            try:\n",
    "                g_cubes = iris.load('./data/mogreps-gg/' + g_fname)\n",
    "                uk_cubes = iris.load('./data/mogreps-uk/' + uk_fname)\n",
    "                uk_cube = uk_cubes[[c.name() for c in uk_cubes].index(param)]\n",
    "                g_cube = g_cubes[[c.name() for c in g_cubes].index(param)]\n",
    "                \n",
    "                uk_cube = uk_cube.extract(iris.Constraint(time=uk_cube.coord('time').points[-1]))\n",
    "                g_cube = g_cube.extract(iris.Constraint(time=uk_cube.coord('time').points[-1]))\n",
    "                print(uk_cube.coord('time'))\n",
    "                \n",
    "                uk_cube, uk_h = get_ground_level(uk_cube)\n",
    "                if uk_h: uk_cube.remove_coord(uk_h)\n",
    "                g_cube, g_h = get_ground_level(g_cube)\n",
    "                if g_h: g_cube.remove_coord(g_h)\n",
    "                    \n",
    "                uk_unrotate = unrotate(uk_cube, g_cube)\n",
    "                g_cube_uk = get_uk_from_global(g_cube, uk_unrotate)\n",
    "\n",
    "                g_regrid = g_cube_uk.regrid(grid=uk_unrotate, scheme=iris.analysis.Nearest())\n",
    "                diff_hr = get_diff(uk_unrotate, g_regrid)\n",
    "                diffs.append(diff_hr)\n",
    "                uks.append(uk_unrotate)\n",
    "                gs.append(g_regrid)\n",
    "            except (IndexError, AttributeError):\n",
    "                pass\n",
    "    return (diffs, uks, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable = 'low_type_cloud_area_fraction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/iris/fileformats/cf.py:1140: IrisDeprecation: NetCDF default loading behaviour currently does not expose variables which define reference surfaces for dimensionless vertical coordinates as independent Cubes. This behaviour is deprecated in favour of automatic promotion to Cubes. To switch to the new behaviour, set iris.FUTURE.netcdf_promote to True.\n",
      "  warn_deprecated(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DimCoord([2016-02-07 06:00:00], standard_name='time', calendar='gregorian', var_name='time_2')\n",
      "DimCoord([2016-02-07 09:00:00], standard_name='time', calendar='gregorian', var_name='time_0')\n",
      "DimCoord([2016-02-07 12:00:00], standard_name='time', calendar='gregorian', var_name='time_0')\n",
      "DimCoord([2016-02-07 15:00:00], standard_name='time', calendar='gregorian', var_name='time_0')\n",
      "DimCoord([2016-02-07 18:00:00], standard_name='time', calendar='gregorian', var_name='time_0')\n",
      "DimCoord([2016-02-07 21:00:00], standard_name='time', calendar='gregorian', var_name='time_0')\n",
      "DimCoord([2016-02-08 00:00:00], standard_name='time', calendar='gregorian', var_name='time_0')\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "diffs, uks, gs = get_diffs(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qplt.pcolormesh(uks[0], cmap='viridis')\n",
    "qplt.show()\n",
    "qplt.pcolormesh(gs[0], cmap='viridis')\n",
    "qplt.show()\n",
    "qplt.pcolormesh(diffs[0], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[pd.collapsed(['latitude', 'longitude'], iris.analysis.RMS).data.item(0) for pd in diffs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diffs_cube = diffs.merge()[0]\n",
    "print(diffs_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_diffs = [iris.analysis.maths.abs(c) for c in diffs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[pd.collapsed(['latitude', 'longitude'], iris.analysis.RMS).data.item(0) for pd in abs_diffs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    qplt.pcolormesh(diffs[i], cmap='viridis')\n",
    "    qplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
